# ğŸ§  Medical NLP Feature Extractor

## ğŸ“Œ Description

Avec l'explosion des donnÃ©es mÃ©dicales non structurÃ©es et la pression croissante sur les systÃ¨mes de santÃ© Ã  opÃ©rer avec des ressources limitÃ©es, le besoin d'automatiser l'analyse de textes cliniques nâ€™a jamais Ã©tÃ© aussi urgent.

Ce projet propose une **pipeline de traitement du langage naturel (NLP)** croisant les performances de **SpaCy** et **SciSpaCy**, deux bibliothÃ¨ques puissantes de NLP â€” la seconde Ã©tant spÃ©cialisÃ©e dans le vocabulaire biomÃ©dical. Ensemble, elles permettent dâ€™extraire automatiquement des informations critiques telles que :
- le nom du patient et du mÃ©decin,
- les pathologies mentionnÃ©es (et leur sÃ©vÃ©ritÃ©),
- les mÃ©dicaments,
- la chronicitÃ© (acuteness) dâ€™une condition mÃ©dicale,
- et si la condition est **niÃ©e ou affirmÃ©e** dans le texte.

> ğŸ¯ Lâ€™objectif Ã  long terme est de **soulager les professionnels de santÃ© des tÃ¢ches redondantes**, en tirant parti des derniÃ¨res avancÃ©es en NLP.

---

## ğŸš€ FonctionnalitÃ©s

- ğŸ“‘ Analyse de corpus mÃ©dical brut ligne par ligne
- ğŸ§  Extraction d'entitÃ©s mÃ©dicales par double-modÃ¨le (SpaCy & SciSpaCy)
- âš–ï¸ Fusion des rÃ©sultats avec **score de confiance pondÃ©rÃ©**
- ğŸ“Š GÃ©nÃ©ration de tableaux :
  - RÃ©sultats d'extraction (`df_results`)
  - Score de confiance (`df_confidence`)
  - Provenance des entitÃ©s (`df_sources`)
- âœ… Ã‰valuation automatique via `df_true` pour mesurer la prÃ©cision
- ğŸ” PrÃªt pour extension vers **BioBERT**, **ClinicalBERT**, et **modÃ¨les gÃ©nÃ©ratifs type Mistral**

---

## ğŸ“‚ Structure du projet

```bash
NER_Project/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus.txt                # Corpus mÃ©dical Ã  analyser
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_extraction.py    # Contient les classes SpaCy et SciSpaCy
â”‚   â”œâ”€â”€ merger.py                # Fusion des rÃ©sultats & calcul des scores
â”‚   â”œâ”€â”€ pipeline.py              # Script principal d'orchestration
â”‚   â””â”€â”€ utils.py                 # Fonctions utilitaires
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ df_true_generator.py     # GÃ©nÃ¨re les labels vrais pour lâ€™Ã©valuation
â”‚   â””â”€â”€ evaluate.py              # Ã‰value l'extraction vs. df_true
â”‚
â”œâ”€â”€ setup/
â”‚   â””â”€â”€ INSTALL.md               # Instructions dâ€™installation dÃ©taillÃ©es
â”‚
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python & modÃ¨les NLP
â””â”€â”€ README.md                    # Ce fichier

```

---

## ğŸ› ï¸ Installation rapide
```bash
git clone https://github.com/votre-utilisateur/NER_Project.git
```

> Voir setup/INSTALL.md pour des instructions plus dÃ©taillÃ©es ou en cas de conflit d'environnement.

--- 

### â–¶ï¸ Utilisation
Placez votre corpus ligne par ligne dans data/corpus.txt

Lancez la pipeline principale :

  ```bash
  python src/pipeline.py
```
Les rÃ©sultats seront sauvegardÃ©s sous forme de DataFrame :

- df_results â†’ RÃ©sultats principaux

- df_confidence â†’ Score de confiance

- df_sources â†’ Source du modÃ¨le utilisÃ©

Pour Ã©valuer la performance :

```bash
python evaluation/evaluate.py
```

--- 

### ğŸ“ˆ Roadmap
- [x] Pipeline rule-based : SpaCy + SciSpaCy

- [ ] IntÃ©gration de BioBERT / ClinicalBERT

- [ ] DÃ©tection multi-entitÃ©s par phrase

- [ ] Support IA gÃ©nÃ©rative (Mistral, Med-GPTâ€¦)

--- 

## ğŸ“¦ Contenu du fichier requirements.txt recommandÃ©
```txt
pandas>=1.3.0
spacy==3.7.2
scispacy==0.5.3
en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1.tar.gz
en_ner_bc5cdr_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_ner_bc5cdr_md-0.5.3.tar.gz
```
---

## ğŸ” ProblÃ¨mes connus
Si vous avez une erreur avec spacy et scispacy ensemble, assurez-vous quâ€™ils utilisent la mÃªme version compatible (3.x).

Sur Mac M1, prÃ©fÃ©rez installer via miniforge et Ã©viter les wheels non optimisÃ©s.

--- 

## ğŸ“„ Licence
Ce projet est sous licence MIT â€“ libre Ã  lâ€™usage acadÃ©mique ou professionnel.
